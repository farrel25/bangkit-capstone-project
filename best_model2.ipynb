{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Classification.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIzO_PZ5dgv3"
      },
      "source": [
        "### **Import Resource**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIsy29TVdgAE"
      },
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtP2Ch2VdOGZ"
      },
      "source": [
        "import tensorflow as tf\n",
        "print('TensorFlow :', tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRPZSLyg5sn6"
      },
      "source": [
        "### **Mounting Google Drive**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HS8MN4QZHLdP"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5aW1lRE6IzE"
      },
      "source": [
        "### **Dataset Directory**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTqUfcMMty3P"
      },
      "source": [
        "import os\n",
        "\n",
        "try:\n",
        "    os.mkdir('/tmp/batik3/')\n",
        "    os.mkdir(os.path.join('/tmp/batik3/', 'training'))\n",
        "    os.mkdir(os.path.join('/tmp/batik3/', 'testing'))\n",
        "    os.mkdir(os.path.join('/tmp/batik3/training', 'ceplok'))\n",
        "    os.mkdir(os.path.join('/tmp/batik3/training', 'megamendung'))\n",
        "    os.mkdir(os.path.join('/tmp/batik3/training', 'kawung'))\n",
        "    os.mkdir(os.path.join('/tmp/batik3/training', 'parang'))\n",
        "    os.mkdir(os.path.join('/tmp/batik3/training', 'sidomukti'))\n",
        "    os.mkdir(os.path.join('/tmp/batik3/testing', 'ceplok'))\n",
        "    os.mkdir(os.path.join('/tmp/batik3/testing', 'megamendung'))\n",
        "    os.mkdir(os.path.join('/tmp/batik3/testing', 'kawung'))\n",
        "    os.mkdir(os.path.join('/tmp/batik3/testing', 'parang'))\n",
        "    os.mkdir(os.path.join('/tmp/batik3/testing', 'sidomukti'))\n",
        "except OSError:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-uDWFeItybg"
      },
      "source": [
        "print('Colab3 Ceplok:', len(os.listdir('/content/drive/Shareddrives/Capstone Project/Dataset/Main Dataset/Colab3/Ceplok/')))\n",
        "print('Colab3 Megamendung:', len(os.listdir('/content/drive/Shareddrives/Capstone Project/Dataset/Main Dataset/Colab3/Megamendung/')))\n",
        "print('Colab3 Kawung:', len(os.listdir('/content/drive/Shareddrives/Capstone Project/Dataset/Main Dataset/Colab3/Kawung/')))\n",
        "print('Colab3 Parang:', len(os.listdir('/content/drive/Shareddrives/Capstone Project/Dataset/Main Dataset/Colab3/Parang/')))\n",
        "print('Colab3 Sidomukti:', len(os.listdir('/content/drive/Shareddrives/Capstone Project/Dataset/Main Dataset/Colab3/Sidomukti/')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6q6gqMbc6RiY"
      },
      "source": [
        "### **Split Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQ9hIQ6ht4LJ"
      },
      "source": [
        "from shutil import copyfile\n",
        "\n",
        "def split_data(SOURCE, TRAINING, TESTING, VALIDATION, SPLIT_SIZE):\n",
        "    # YOUR CODE STARTS HERE\n",
        "    if not os.path.exists(TRAINING): \n",
        "        os.makedirs(TRAINING) \n",
        "                \n",
        "    if not os.path.exists(TESTING): \n",
        "        os.makedirs(TESTING) \n",
        "\n",
        "    if not os.path.exists(VALIDATION): \n",
        "        os.makedirs(VALIDATION)\n",
        "\n",
        "    file_names = os.listdir(SOURCE) \n",
        "    file_number = len(file_names) \n",
        "\n",
        "    for index, file in enumerate(file_names): \n",
        "        if index < SPLIT_SIZE * file_number: \n",
        "          if index < 0.8 * file_number:\n",
        "            copyfile(os.path.join(SOURCE, file), os.path.join(TRAINING, file))\n",
        "          else:\n",
        "            copyfile(os.path.join(SOURCE, file), os.path.join(VALIDATION, file))\n",
        "        else: \n",
        "            copyfile(os.path.join(SOURCE, file), os.path.join(TESTING, file)) \n",
        "        \n",
        "CEPLOK_SOURCE_DIR = \"/content/drive/Shareddrives/Capstone Project/Dataset/Main Dataset/Colab3/Ceplok/\"\n",
        "MEGAMENDUNG_SOURCE_DIR = \"/content/drive/Shareddrives/Capstone Project/Dataset/Main Dataset/Colab3/Megamendung/\"\n",
        "KAWUNG_SOURCE_DIR = \"/content/drive/Shareddrives/Capstone Project/Dataset/Main Dataset/Colab3/Kawung/\"\n",
        "PARANG_SOURCE_DIR = \"/content/drive/Shareddrives/Capstone Project/Dataset/Main Dataset/Colab3/Parang/\"\n",
        "SIDOMUKTI_SOURCE_DIR = \"/content/drive/Shareddrives/Capstone Project/Dataset/Main Dataset/Colab3/Sidomukti/\"\n",
        "\n",
        "TRAINING_CEPLOK_DIR = \"/tmp/batik3/training/ceplok/\"\n",
        "TRAINING_MEGAMENDUNG_DIR = \"/tmp/batik3/training/megamendung/\"\n",
        "TRAINING_KAWUNG_DIR = \"/tmp/batik3/training/kawung/\"\n",
        "TRAINING_PARANG_DIR = \"/tmp/batik3/training/parang/\"\n",
        "TRAINING_SIDOMUKTI_DIR = \"/tmp/batik3/training/sidomukti/\"\n",
        "\n",
        "TESTING_CEPLOK_DIR = \"/tmp/batik3/testing/ceplok/\"\n",
        "TESTING_MEGAMENDUNG_DIR = \"/tmp/batik3/testing/megamendung/\"\n",
        "TESTING_KAWUNG_DIR = \"/tmp/batik3/testing/kawung/\"\n",
        "TESTING_PARANG_DIR = \"/tmp/batik3/testing/parang/\"\n",
        "TESTING_SIDOMUKTI_DIR = \"/tmp/batik3/testing/sidomukti/\"\n",
        "\n",
        "VALIDATION_CEPLOK_DIR = \"/tmp/batik3/validation/ceplok/\"\n",
        "VALIDATION_MEGAMENDUNG_DIR = \"/tmp/batik3/validation/megamendung/\"\n",
        "VALIDATION_KAWUNG_DIR = \"/tmp/batik3/validation/kawung/\"\n",
        "VALIDATION_PARANG_DIR = \"/tmp/batik3/validation/parang/\"\n",
        "VALIDATION_SIDOMUKTI_DIR = \"/tmp/batik3/validation/sidomukti/\"\n",
        "\n",
        "\n",
        "split_size = .9\n",
        "split_data(CEPLOK_SOURCE_DIR, TRAINING_CEPLOK_DIR, TESTING_CEPLOK_DIR, VALIDATION_CEPLOK_DIR, split_size)\n",
        "split_data(MEGAMENDUNG_SOURCE_DIR, TRAINING_MEGAMENDUNG_DIR, TESTING_MEGAMENDUNG_DIR, VALIDATION_MEGAMENDUNG_DIR, split_size)\n",
        "split_data(KAWUNG_SOURCE_DIR, TRAINING_KAWUNG_DIR, TESTING_KAWUNG_DIR, VALIDATION_KAWUNG_DIR, split_size)\n",
        "split_data(PARANG_SOURCE_DIR, TRAINING_PARANG_DIR, TESTING_PARANG_DIR, VALIDATION_PARANG_DIR, split_size)\n",
        "split_data(SIDOMUKTI_SOURCE_DIR, TRAINING_SIDOMUKTI_DIR, TESTING_SIDOMUKTI_DIR, VALIDATION_SIDOMUKTI_DIR, split_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KIW0262t6bd"
      },
      "source": [
        "train_ceplok = os.listdir(TRAINING_CEPLOK_DIR)\n",
        "train_megamendung = os.listdir(TRAINING_MEGAMENDUNG_DIR)\n",
        "train_kawung = os.listdir(TRAINING_KAWUNG_DIR)\n",
        "train_parang = os.listdir(TRAINING_PARANG_DIR)\n",
        "train_sidomukti = os.listdir(TRAINING_SIDOMUKTI_DIR)\n",
        "\n",
        "test_ceplok = os.listdir(TESTING_CEPLOK_DIR)\n",
        "test_megamendung = os.listdir(TESTING_MEGAMENDUNG_DIR)\n",
        "test_kawung = os.listdir(TESTING_KAWUNG_DIR)\n",
        "test_parang = os.listdir(TESTING_PARANG_DIR)\n",
        "test_sidomukti = os.listdir(TESTING_SIDOMUKTI_DIR)\n",
        "\n",
        "val_ceplok = os.listdir(VALIDATION_CEPLOK_DIR)\n",
        "val_megamendung = os.listdir(VALIDATION_MEGAMENDUNG_DIR)\n",
        "val_kawung = os.listdir(VALIDATION_KAWUNG_DIR)\n",
        "val_parang = os.listdir(VALIDATION_PARANG_DIR)\n",
        "val_sidomukti = os.listdir(VALIDATION_SIDOMUKTI_DIR)\n",
        "\n",
        "print(\"Training\")\n",
        "print('Ceplok :', len(train_ceplok))\n",
        "print('Megamendung :', len(train_megamendung))\n",
        "print('Kawung :', len(train_kawung))\n",
        "print('Parang :', len(train_parang))\n",
        "print('Sidomukti :', len(train_sidomukti))\n",
        "\n",
        "print(\"\\nTesting\")\n",
        "print('Ceplok :', len(test_ceplok))\n",
        "print('Megamendung :', len(test_megamendung))\n",
        "print('Kawung :', len(test_kawung))\n",
        "print('Parang :', len(test_parang))\n",
        "print('Sidomukti :', len(test_sidomukti))\n",
        "\n",
        "print(\"\\nValidation\")\n",
        "print('Ceplok :', len(val_ceplok))\n",
        "print('Megamendung :', len(val_megamendung))\n",
        "print('Kawung :', len(val_kawung))\n",
        "print('Parang :', len(val_parang))\n",
        "print('Sidomukti :', len(val_sidomukti))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXINbsZJ0KPA"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras_preprocessing import image\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "TRAINING_DIR = '/tmp/batik3/training/'\n",
        "train_datagen = image.ImageDataGenerator(\n",
        "    rescale=1.0/255.0,\n",
        "    rotation_range=45,\n",
        "    width_shift_range=0.25,\n",
        "    height_shift_range=0.25,\n",
        "    shear_range=0.25,\n",
        "    zoom_range=0.25,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    TRAINING_DIR, \n",
        "    class_mode='categorical', \n",
        "    batch_size=BATCH_SIZE, \n",
        "    target_size=IMG_SIZE, \n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "\n",
        "TESTING_DIR = '/tmp/batik3/testing/'\n",
        "datagen = image.ImageDataGenerator(rescale = 1.0/255.0)\n",
        "\n",
        "test_generator = datagen.flow_from_directory(\n",
        "    TESTING_DIR, \n",
        "    class_mode='categorical', \n",
        "    batch_size=BATCH_SIZE, \n",
        "    target_size=IMG_SIZE,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "\n",
        "VALIDATION_DIR = '/tmp/batik3/validation/'\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    VALIDATION_DIR, \n",
        "    class_mode='categorical', \n",
        "    batch_size=BATCH_SIZE, \n",
        "    target_size=IMG_SIZE,\n",
        "    shuffle=True\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fl_jMKwe1HaJ"
      },
      "source": [
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "train_dataset = image_dataset_from_directory(TRAINING_DIR,\n",
        "                                             shuffle=True,\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             image_size=IMG_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soO2AN5JF3mW"
      },
      "source": [
        "class_names = train_dataset.class_names\n",
        "\n",
        "print(class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5azApBZVGAS2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(13, 13))\n",
        "for images, labels in train_dataset.take(1):\n",
        "  for i in range(16):\n",
        "    ax = plt.subplot(4, 4, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "udf9xAqzG114"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    # This is the first convolution\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=IMG_SIZE + (3,)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The third convolution\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    # Using dropouts\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(5, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dhQXfV_8JnLh"
      },
      "source": [
        "learning_rate = 0.0001\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "t0tTFpo8KbfY"
      },
      "source": [
        "history = model.fit(train_generator,\n",
        "                    epochs=10,\n",
        "                    steps_per_epoch=len(train_generator),\n",
        "                    validation_data=val_generator,\n",
        "                    verbose = 1,\n",
        "                    validation_steps=len(val_generator))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "C7BAgb20L2WR"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc)) # Get number of epochs\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQcjfctZsHzY"
      },
      "source": [
        "### **Train Model with Transfer Learning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6t3T1q4MsNex"
      },
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "pretrained_model = InceptionV3(input_shape = (224, 224, 3),\n",
        "                                include_top = False,\n",
        "                                weights ='imagenet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrQwZvYkk9qH"
      },
      "source": [
        "for layer in pretrained_model.layers:\n",
        "    layer.trainable = False\n",
        "    \n",
        "# Print the model summary\n",
        "pretrained_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwXT3kWS3dQR"
      },
      "source": [
        "last_layer = pretrained_model.get_layer('mixed6')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lneCc0xJ2gIf"
      },
      "source": [
        "#model2 = tf.keras.Sequential([\n",
        "#  pretrained_model,\n",
        "#  tf.keras.layers.Flatten(),\n",
        "#  tf.keras.layers.Dense(512, activation='relu'),\n",
        "#  tf.keras.layers.Dropout(0.2),\n",
        "#  tf.keras.layers.Dense(5, activation='softmax')\n",
        "#])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ljanj4DG4fLN"
      },
      "source": [
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(5, activation='softmax')(x)           "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oOd3Juz5TCl"
      },
      "source": [
        "model2 = Model(pretrained_model.input, x) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiiykFEo4OmK"
      },
      "source": [
        "model2.compile(optimizer=tf.keras.optimizers.Adam(0.0001), \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PDicSCmxsId"
      },
      "source": [
        "history = model2.fit(train_generator, \n",
        "                     epochs=20, \n",
        "                     steps_per_epoch=10, \n",
        "                     validation_data=val_generator, \n",
        "                     validation_steps=3,\n",
        "                     verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWw9q_Ng0NxK"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc)) # Get number of epochs\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlPSInCz6oMt"
      },
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from tensorflow.keras.applications.xception import preprocess_input\n",
        "\n",
        "labels = train_generator.class_indices.keys()\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = fn\n",
        "  img = image.load_img(path, target_size=(224, 224))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  x = preprocess_input(x)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  proba = model2.predict(images)[0]\n",
        "  plt.imshow(img)\n",
        "  plt.show()\n",
        "  for (label, p) in zip(labels, proba):\n",
        "    print(\"{}: {:.2f}%\".format(label, p * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LW5ODCMSpIqV"
      },
      "source": [
        "### **Save the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3iPr6DjXfi_"
      },
      "source": [
        "saved_model_path = \"/content/image_classification.h5\"\n",
        "\n",
        "# Save model h5\n",
        "model2.save(saved_model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0R108WR4bk7l"
      },
      "source": [
        "### **Convert Saved Model to Tensorflow.js** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3-QsPhbbjf6"
      },
      "source": [
        "!tensorflowjs_converter --input_format=keras {saved_model_path} '/content/drive/MyDrive/best_model'"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}